{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('descriptions.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print lines[0]\n",
    "print lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title', 'description'])\n",
    "\n",
    "numDescriptions = 0\n",
    "index = 0\n",
    "while numDescriptions < 143:\n",
    "    title = ' '.join(lines[index].strip().split(' ')[1:])\n",
    "    description = ''\n",
    "    index = index + 1\n",
    "    while not lines[index] == '\\n':\n",
    "        description = description + ' ' + lines[index]\n",
    "        index = index + 1\n",
    "    index = index + 1\n",
    "    \n",
    "    df.loc[numDescriptions] = [title, description.strip()]\n",
    "    numDescriptions = numDescriptions + 1\n",
    "    \n",
    "df.to_pickle('descriptions.pkl')\n",
    "\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract bigram matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,2), stop_words = ENGLISH_STOP_WORDS)\n",
    "X = vect.fit_transform(df.description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=5,max_iter = 100)\n",
    "y = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# 1) Print out what words appear most frequently in each topic\n",
    "# 2) Scatter plot the documents (in 2-D or 3-D space)\n",
    "# 3) Gather statistics (e.g. the ratio of student/normal tickets for each topic)\n",
    "# 4) Try other topic modeling methods (tf-idf, SVD, other flavors of LDA, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out what words appear most frequently in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I copy this code from example on sklearn \n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_top_words = 50\n",
    "\n",
    "print_top_words(lda, vect.get_feature_names(), n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot the documents (in 2-D or 3-D space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## determine which topic for each show\n",
    "doc_topics = []\n",
    "num_documents = y.shape[0]\n",
    "for doc in range(num_documents):\n",
    "    t = y[doc, :].argmax()\n",
    "    doc_topics.append([doc, df.title[doc], t, y[doc, t]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topic = pd.DataFrame(np.array(doc_topics), columns = ['index', 'perf_name', 'topic_num', 'score'])\n",
    "df_topic.topic_num = df_topic.topic_num.astype(dtype = np.int16)\n",
    "df_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## plot the distribution of the performance for each topic\n",
    "import seaborn as sns\n",
    "topic_range = range(5)\n",
    "sns.factorplot(x = 'topic_num', data = df_topic, kind = 'count', palette=\"BuPu\", size=6, aspect=1.5, order = topic_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
